# ----- Required (user will be prompted to fill MISTRAL_API_KEY) -----
MISTRAL_API_KEY=
MISTRAL_MODEL=mistral-small-latest

# ----- vLLM (offline) -----
VLLM_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0
VLLM_API_KEY=testingvllm
VLLM_GPU_MEM=0.7

# ----- Ports -----
PORT_API_ONLINE=8090
PORT_API_OFFLINE=8080
PORT_CHAT=3000
PORT_VLLM=8000

# ----- CORS -----
CORS_ORIGINS=http://localhost:3000

# ----- Frontend public config (safe for browser) -----
NEXT_PUBLIC_ONLINE_ENDPOINT=http://localhost:${PORT_API_ONLINE}/response
NEXT_PUBLIC_VLLM_CHAT=http://localhost:${PORT_API_OFFLINE}/vllm/chat
NEXT_PUBLIC_VLLM_MODEL=${VLLM_MODEL}
NEXT_PUBLIC_OFFLINE_API_KEY=${VLLM_API_KEY}
